{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iris 데이터셋 활용해서 꽃잎 너비 예측 모델\n",
    " - 데이터셋 : iris.csv에서 2개의 Feature 사용\n",
    " - 구현프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] 모듈 로딩 및 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch                                 # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn                        # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F              # 손실, 거래 등 함수 관련 모듈 \n",
    "import torch.optim as optimizer              # 최적화 기법 관련 모듈\n",
    "from torchmetrics.regression import R2Score  # 성능지표 관련 모듈  - 추가 설치\n",
    "from torchinfo import summary                # 모델 정보 관련 모듈 - 추가 설치\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE => cpu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 및 절편 값 고정 설정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 저장 및 실행 위치 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'DEVICE => {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1-1] 데이터 로딩\n",
    "irisDF = pd.read_csv(r'C:\\VSCode\\KDT\\Torch_DL\\Data\\iris.csv',usecols=[0,1,2,3])\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 준비\n",
    " - 학습방법 : 지도학습 > 회귀\n",
    " - 알고리즘 : 선형관계 >> 선형모델 ==> nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "# 입력층에 입력값 => sepal.length, sepal.width, petal.length 3개\n",
    "# 출력층의 출력값/타겟 => petal.width 1개\n",
    "# 입력층    :  입력 피쳐3, 출력 입력층에 존재하는 퍼셉트론 개수 10, AF ReLU\n",
    "#                          |\n",
    "#                -----------\n",
    "#                | ReLU\n",
    "#                V          \n",
    "# 은닉층    :  입력 10, 출력 은닉층에 존재하는 퍼셉트론 개수 5, AF ReLU\n",
    "#                       |\n",
    "#                -------\n",
    "#                | ReLU\n",
    "#                v\n",
    "# 출력층    :  입력 5, 출력 타겟/라벨 개수 1 , AF - None\n",
    "model = nn.Sequential(nn.Linear(3,10),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(10,5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [20000, 1]                --\n",
       "├─Linear: 1-1                            [20000, 10]               40\n",
       "├─ReLU: 1-2                              [20000, 10]               --\n",
       "├─Linear: 1-3                            [20000, 5]                55\n",
       "├─ReLU: 1-4                              [20000, 5]                --\n",
       "├─Linear: 1-5                            [20000, 1]                6\n",
       "==========================================================================================\n",
       "Total params: 101\n",
       "Trainable params: 101\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.24\n",
       "Forward/backward pass size (MB): 2.56\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 2.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "print(model)\n",
    "summary(model,input_size=(20000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.weight], [Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119],\n",
      "        [ 0.2710, -0.5435,  0.3462],\n",
      "        [-0.1188,  0.2937,  0.0803],\n",
      "        [-0.0707,  0.1601,  0.0285],\n",
      "        [ 0.2109, -0.2250, -0.0421],\n",
      "        [-0.0520,  0.0837, -0.0023],\n",
      "        [ 0.5047,  0.1797, -0.2150],\n",
      "        [-0.3487, -0.0968, -0.2490],\n",
      "        [-0.1850,  0.0276,  0.3442],\n",
      "        [ 0.3138, -0.5644,  0.3579]], requires_grad=True)],\"\n",
      "\"\n",
      "[0.bias], [Parameter containing:\n",
      "tensor([ 0.1613,  0.5476,  0.3811, -0.5260, -0.5489, -0.2785,  0.5070, -0.0962,\n",
      "         0.2471, -0.2683], requires_grad=True)],\"\n",
      "\"\n",
      "[2.weight], [Parameter containing:\n",
      "tensor([[ 0.3103, -0.1338,  0.2371,  0.0037, -0.1666,  0.1625, -0.1679,  0.0930,\n",
      "         -0.0913, -0.0347],\n",
      "        [-0.3040, -0.1508,  0.1716, -0.0769,  0.3150,  0.2535, -0.0148, -0.2111,\n",
      "          0.1926,  0.0981],\n",
      "        [-0.2044,  0.2054,  0.1920,  0.2805, -0.1773, -0.0521, -0.0061,  0.0462,\n",
      "         -0.2400, -0.2244],\n",
      "        [ 0.1720, -0.0742,  0.1545,  0.0180,  0.1038,  0.0695,  0.1150,  0.1568,\n",
      "         -0.2929,  0.1592],\n",
      "        [-0.2223, -0.2386,  0.0192, -0.0539,  0.1857, -0.1831, -0.2811,  0.2301,\n",
      "         -0.0469,  0.1779]], requires_grad=True)],\"\n",
      "\"\n",
      "[2.bias], [Parameter containing:\n",
      "tensor([ 0.1017, -0.2371,  0.0635,  0.0760, -0.2117], requires_grad=True)],\"\n",
      "\"\n",
      "[4.weight], [Parameter containing:\n",
      "tensor([[-0.2122,  0.1525,  0.0801, -0.1902, -0.1354]], requires_grad=True)],\"\n",
      "\"\n",
      "[4.bias], [Parameter containing:\n",
      "tensor([0.4096], requires_grad=True)],\"\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 절편 확인\n",
    "for name, name_parameter in model.named_parameters() :\n",
    "    print(f'[{name}], [{name_parameter}],\"\\n\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 최적화 인스턴스 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델의 가중치와 절편 최적화 이후 인스턴스에 전달\n",
    "adam_optimizer = optimizer.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 진행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [4-1] 데이터셋 Tensor화 진행 : 데이터 준비 시 진행 or 학습 전 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length'], dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타겟 분리\n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetDF = irisDF[['petal.width']]\n",
    "\n",
    "print(featureDF.shape, targetDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF,\n",
    "                                                    targetDF,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=5)\n",
    "\n",
    "# Train, Valid\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                   test_size = 0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [4-2] 학습진행 : \n",
    "   * 학습횟수 결정 ==> 에포크 설정\n",
    "   * 배치크기 결정 \n",
    "   * 배치개수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:100, BATCH_SIZE:12, BATCH_CNT:8\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 100                             # 처음~끝까지 공부하는 횟수\n",
    "BATCH_SIZE = 12                         # 1에포크에서 한 번 학습할 분량 크기\n",
    "BATCH_CNT = X_train.shape[0]//BATCH_SIZE # 1에포크에서 총 학습 횟수이면서 업데이트 횟수\n",
    "# 몫 연산자 이용해서 구함. 나머지 6개는 사용이 안됨.\n",
    "print(f'EPOCH:{EPOCH}, BATCH_SIZE:{BATCH_SIZE}, BATCH_CNT:{BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트/검증 함수 \n",
    "# ==> 가중치,절편 업데이트 X 그래서 최적화 미진행 해야함\n",
    "# ==> 현재 가중치와 절편으로 테스트 진행\n",
    "def testing(testDF, targetDF, kind = 'Val') :\n",
    "    # Tensor화\n",
    "    testTS = torch.FloatTensor(testDF.values).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad() :      # 가중치 및 절편 업데이트 X\n",
    "        # (1) 학습진행 forward\n",
    "        pre_y = model(testTS)\n",
    "\n",
    "        # (2) 오차계산 - 손실함수\n",
    "        loss = F.mse_loss(pre_y, targetTS)\n",
    "\n",
    "        # (3) 성능평가 - R2\n",
    "        r2 = R2Score()(pre_y,targetTS)\n",
    "       \n",
    "        # (3) 학습 과정 출력 및 저장\n",
    "        print(f'[{kind}] LOSS : {loss},R2 : {r2}')\n",
    "\n",
    "    return loss, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def training(featureTS, targetTS, valTS, valTargetTS) :\n",
    "    # [[],[]] <= [train,val]\n",
    "    loss_history = [[],[]]\n",
    "    r2_history=[[],[]]\n",
    "\n",
    "    for epoch in range(EPOCH) :\n",
    "        # 배치 손실 저장 변수\n",
    "        bs_loss,bs_r2=0,0\n",
    "\n",
    "        # 배치크기 만큼 학습 진행\n",
    "        for i in range(BATCH_CNT):\n",
    "            start=i*BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "            print(start,end)\n",
    "            # BATCH_SIZE 크기만큼만 데이터 추출해서 Tensor화 진행\n",
    "            BSX_train = torch.FloatTensor(X_train[start:end].values).to(DEVICE)\n",
    "            BSy_train = torch.FloatTensor(y_train[start:end].values).to(DEVICE)\n",
    "\n",
    "            # print(BSX_train.shape, BSX_train.device,BSX_train.dtype)\n",
    "            # print(BSy_train.shape, BSy_train.device,BSy_train.dtype)\n",
    "        # (1) 학습진행 forward\n",
    "        pre_y = model(BSX_train)\n",
    "        print(f'pre_y.shape : {pre_y.shape}')\n",
    "\n",
    "        # (2) 오차계산 - 손실함수\n",
    "        loss = F.mse_loss(pre_y, BSy_train)\n",
    "        bs_loss += loss.item()\n",
    "        bs_r2 += R2Score()(pre_y,BSy_train).item()\n",
    "       \n",
    "        # (3) 최적화 - 가중치, 절편 업데이트\n",
    "        adam_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        adam_optimizer.step()\n",
    "\n",
    "        # -(4) 검증 - 모델이 제대로 만들어지는 검사용\n",
    "        val_loss,val_r2 = testing(valTS,valTargetTS)\n",
    "        loss_history[1].append(val_loss.item())\n",
    "        r2_history[1].append(val_r2.item())\n",
    "\n",
    "        # 에포크 단위 손실과 성능지표\n",
    "        loss_history[0].append(bs_loss/BATCH_CNT)\n",
    "        r2_history[0].append(bs_r2/BATCH_CNT)\n",
    "\n",
    "        # (4) 학습 과정 출력\n",
    "        print(f'[{epoch}/{EPOCH}]\\n Train LOSS : {loss_history[0][-1]} R2 : {r2_history[0][-1]}')\n",
    "        print(f'-VALID LOSS : {loss_history[1][-1]} R2 : {r2_history[1][-1]}')\n",
    "\n",
    "    return loss_history, r2_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.5848502516746521,R2 : -0.4013630151748657\n",
      "[0/100]\n",
      " Train LOSS : 0.11050643771886826 R2 : -0.19764670729637146\n",
      "-VALID LOSS : 0.5848502516746521 R2 : -0.4013630151748657\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.31909462809562683,R2 : 0.23541557788848877\n",
      "[1/100]\n",
      " Train LOSS : 0.05616157874464989 R2 : -0.038975492119789124\n",
      "-VALID LOSS : 0.31909462809562683 R2 : 0.23541557788848877\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.44660958647727966,R2 : -0.07012379169464111\n",
      "[2/100]\n",
      " Train LOSS : 0.033388663083314896 R2 : 0.027514800429344177\n",
      "-VALID LOSS : 0.44660958647727966 R2 : -0.07012379169464111\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.2999894618988037,R2 : 0.2811935544013977\n",
      "[3/100]\n",
      " Train LOSS : 0.059474777430295944 R2 : -0.04864907264709473\n",
      "-VALID LOSS : 0.2999894618988037 R2 : 0.2811935544013977\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.2958374619483948,R2 : 0.29114216566085815\n",
      "[4/100]\n",
      " Train LOSS : 0.036092039197683334 R2 : 0.019621722400188446\n",
      "-VALID LOSS : 0.2958374619483948 R2 : 0.29114216566085815\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.3616058826446533,R2 : 0.1335541009902954\n",
      "[5/100]\n",
      " Train LOSS : 0.029840275645256042 R2 : 0.03787505626678467\n",
      "-VALID LOSS : 0.3616058826446533 R2 : 0.1335541009902954\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.3936042785644531,R2 : 0.05688256025314331\n",
      "[6/100]\n",
      " Train LOSS : 0.03442634269595146 R2 : 0.024485081434249878\n",
      "-VALID LOSS : 0.3936042785644531 R2 : 0.05688256025314331\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.38157984614372253,R2 : 0.08569437265396118\n",
      "[7/100]\n",
      " Train LOSS : 0.03712105751037598 R2 : 0.016617290675640106\n",
      "-VALID LOSS : 0.38157984614372253 R2 : 0.08569437265396118\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.3364756107330322,R2 : 0.19376885890960693\n",
      "[8/100]\n",
      " Train LOSS : 0.03590769320726395 R2 : 0.02015995979309082\n",
      "-VALID LOSS : 0.3364756107330322 R2 : 0.19376885890960693\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.27718114852905273,R2 : 0.33584463596343994\n",
      "[9/100]\n",
      " Train LOSS : 0.03182058408856392 R2 : 0.03209313005208969\n",
      "-VALID LOSS : 0.27718114852905273 R2 : 0.33584463596343994\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.23086445033550262,R2 : 0.4468243718147278\n",
      "[10/100]\n",
      " Train LOSS : 0.02703195996582508 R2 : 0.0460745245218277\n",
      "-VALID LOSS : 0.23086445033550262 R2 : 0.4468243718147278\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.21570420265197754,R2 : 0.4831499457359314\n",
      "[11/100]\n",
      " Train LOSS : 0.02457721345126629 R2 : 0.05324167758226395\n",
      "-VALID LOSS : 0.21570420265197754 R2 : 0.4831499457359314\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.206937775015831,R2 : 0.5041552186012268\n",
      "[12/100]\n",
      " Train LOSS : 0.025782383978366852 R2 : 0.04972292482852936\n",
      "-VALID LOSS : 0.206937775015831 R2 : 0.5041552186012268\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.17850632965564728,R2 : 0.5722799301147461\n",
      "[13/100]\n",
      " Train LOSS : 0.026112983003258705 R2 : 0.04875767230987549\n",
      "-VALID LOSS : 0.17850632965564728 R2 : 0.5722799301147461\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.15567146241664886,R2 : 0.6269947290420532\n",
      "[14/100]\n",
      " Train LOSS : 0.021743260324001312 R2 : 0.06151599436998367\n",
      "-VALID LOSS : 0.15567146241664886 R2 : 0.6269947290420532\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.15936876833438873,R2 : 0.6181355714797974\n",
      "[15/100]\n",
      " Train LOSS : 0.016687268391251564 R2 : 0.07627801597118378\n",
      "-VALID LOSS : 0.15936876833438873 R2 : 0.6181355714797974\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.17383216321468353,R2 : 0.5834797620773315\n",
      "[16/100]\n",
      " Train LOSS : 0.015238749794661999 R2 : 0.08050727844238281\n",
      "-VALID LOSS : 0.17383216321468353 R2 : 0.5834797620773315\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.16620726883411407,R2 : 0.601749837398529\n",
      "[17/100]\n",
      " Train LOSS : 0.015731578692793846 R2 : 0.07906836271286011\n",
      "-VALID LOSS : 0.16620726883411407 R2 : 0.601749837398529\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.1273302435874939,R2 : 0.6949032545089722\n",
      "[18/100]\n",
      " Train LOSS : 0.014534001238644123 R2 : 0.08256493508815765\n",
      "-VALID LOSS : 0.1273302435874939 R2 : 0.6949032545089722\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.08005531877279282,R2 : 0.8081790208816528\n",
      "[19/100]\n",
      " Train LOSS : 0.011103211902081966 R2 : 0.0925818458199501\n",
      "-VALID LOSS : 0.08005531877279282 R2 : 0.8081790208816528\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05709134042263031,R2 : 0.8632031083106995\n",
      "[20/100]\n",
      " Train LOSS : 0.007953658699989319 R2 : 0.10177762806415558\n",
      "-VALID LOSS : 0.05709134042263031 R2 : 0.8632031083106995\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.054549917578697205,R2 : 0.8692926168441772\n",
      "[21/100]\n",
      " Train LOSS : 0.00807584822177887 R2 : 0.10142086446285248\n",
      "-VALID LOSS : 0.054549917578697205 R2 : 0.8692926168441772\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04672246053814888,R2 : 0.8880480527877808\n",
      "[22/100]\n",
      " Train LOSS : 0.008941047824919224 R2 : 0.09889473766088486\n",
      "-VALID LOSS : 0.04672246053814888 R2 : 0.8880480527877808\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05504775047302246,R2 : 0.8680997490882874\n",
      "[23/100]\n",
      " Train LOSS : 0.006574244704097509 R2 : 0.10580511391162872\n",
      "-VALID LOSS : 0.05504775047302246 R2 : 0.8680997490882874\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0822056457400322,R2 : 0.803026556968689\n",
      "[24/100]\n",
      " Train LOSS : 0.004767171572893858 R2 : 0.11108124256134033\n",
      "-VALID LOSS : 0.0822056457400322 R2 : 0.803026556968689\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.08912225812673569,R2 : 0.7864536643028259\n",
      "[25/100]\n",
      " Train LOSS : 0.005678031127899885 R2 : 0.10842180252075195\n",
      "-VALID LOSS : 0.08912225812673569 R2 : 0.7864536643028259\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0609685480594635,R2 : 0.8539129495620728\n",
      "[26/100]\n",
      " Train LOSS : 0.005846660118550062 R2 : 0.10792945325374603\n",
      "-VALID LOSS : 0.0609685480594635 R2 : 0.8539129495620728\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03615889325737953,R2 : 0.9133594632148743\n",
      "[27/100]\n",
      " Train LOSS : 0.003665560157969594 R2 : 0.11429762840270996\n",
      "-VALID LOSS : 0.03615889325737953 R2 : 0.9133594632148743\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04220890998840332,R2 : 0.8988629579544067\n",
      "[28/100]\n",
      " Train LOSS : 0.002945281332358718 R2 : 0.11640063673257828\n",
      "-VALID LOSS : 0.04220890998840332 R2 : 0.8988629579544067\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.07514384388923645,R2 : 0.8199474215507507\n",
      "[29/100]\n",
      " Train LOSS : 0.004233397543430328 R2 : 0.11263971030712128\n",
      "-VALID LOSS : 0.07514384388923645 R2 : 0.8199474215507507\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.049551691859960556,R2 : 0.8812689185142517\n",
      "[30/100]\n",
      " Train LOSS : 0.004350272938609123 R2 : 0.11229846626520157\n",
      "-VALID LOSS : 0.049551691859960556 R2 : 0.8812689185142517\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04590770602226257,R2 : 0.8900002837181091\n",
      "[31/100]\n",
      " Train LOSS : 0.003631020663306117 R2 : 0.11439847201108932\n",
      "-VALID LOSS : 0.04590770602226257 R2 : 0.8900002837181091\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05418580397963524,R2 : 0.8701651096343994\n",
      "[32/100]\n",
      " Train LOSS : 0.003579590702429414 R2 : 0.11454863846302032\n",
      "-VALID LOSS : 0.05418580397963524 R2 : 0.8701651096343994\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.06167982146143913,R2 : 0.8522086143493652\n",
      "[33/100]\n",
      " Train LOSS : 0.003046884201467037 R2 : 0.11610398441553116\n",
      "-VALID LOSS : 0.06167982146143913 R2 : 0.8522086143493652\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05365703999996185,R2 : 0.8714320659637451\n",
      "[34/100]\n",
      " Train LOSS : 0.003181656589731574 R2 : 0.11571048945188522\n",
      "-VALID LOSS : 0.05365703999996185 R2 : 0.8714320659637451\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04635252431035042,R2 : 0.8889344334602356\n",
      "[35/100]\n",
      " Train LOSS : 0.0029097534716129303 R2 : 0.11650436371564865\n",
      "-VALID LOSS : 0.04635252431035042 R2 : 0.8889344334602356\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04746592044830322,R2 : 0.8862666487693787\n",
      "[36/100]\n",
      " Train LOSS : 0.003044901182875037 R2 : 0.11610977351665497\n",
      "-VALID LOSS : 0.04746592044830322 R2 : 0.8862666487693787\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05624935403466225,R2 : 0.8652206063270569\n",
      "[37/100]\n",
      " Train LOSS : 0.003062579780817032 R2 : 0.11605815589427948\n",
      "-VALID LOSS : 0.05624935403466225 R2 : 0.8652206063270569\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0637560486793518,R2 : 0.847233772277832\n",
      "[38/100]\n",
      " Train LOSS : 0.0029700181912630796 R2 : 0.1163284108042717\n",
      "-VALID LOSS : 0.0637560486793518 R2 : 0.847233772277832\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05849429592490196,R2 : 0.8598414659500122\n",
      "[39/100]\n",
      " Train LOSS : 0.0031655889470130205 R2 : 0.11575739830732346\n",
      "-VALID LOSS : 0.05849429592490196 R2 : 0.8598414659500122\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05180924013257027,R2 : 0.8758595585823059\n",
      "[40/100]\n",
      " Train LOSS : 0.003045733319595456 R2 : 0.11610734462738037\n",
      "-VALID LOSS : 0.05180924013257027 R2 : 0.8758595585823059\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.053657177835702896,R2 : 0.8714317083358765\n",
      "[41/100]\n",
      " Train LOSS : 0.0031755445525050163 R2 : 0.11572833359241486\n",
      "-VALID LOSS : 0.053657177835702896 R2 : 0.8714317083358765\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.06205740198493004,R2 : 0.8513039350509644\n",
      "[42/100]\n",
      " Train LOSS : 0.0031241094693541527 R2 : 0.11587850749492645\n",
      "-VALID LOSS : 0.06205740198493004 R2 : 0.8513039350509644\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.06267144531011581,R2 : 0.8498325943946838\n",
      "[43/100]\n",
      " Train LOSS : 0.0031329079065471888 R2 : 0.11585281789302826\n",
      "-VALID LOSS : 0.06267144531011581 R2 : 0.8498325943946838\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.053925614804029465,R2 : 0.8707885146141052\n",
      "[44/100]\n",
      " Train LOSS : 0.0031418956350535154 R2 : 0.1158265769481659\n",
      "-VALID LOSS : 0.053925614804029465 R2 : 0.8707885146141052\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05055079981684685,R2 : 0.8788749575614929\n",
      "[45/100]\n",
      " Train LOSS : 0.003042773576453328 R2 : 0.1161159873008728\n",
      "-VALID LOSS : 0.05055079981684685 R2 : 0.8788749575614929\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05503404140472412,R2 : 0.8681325912475586\n",
      "[46/100]\n",
      " Train LOSS : 0.0030695830937474966 R2 : 0.11603771150112152\n",
      "-VALID LOSS : 0.05503404140472412 R2 : 0.8681325912475586\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.057909924536943436,R2 : 0.8612416982650757\n",
      "[47/100]\n",
      " Train LOSS : 0.0029336323495954275 R2 : 0.11643464863300323\n",
      "-VALID LOSS : 0.057909924536943436 R2 : 0.8612416982650757\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05124422907829285,R2 : 0.8772134184837341\n",
      "[48/100]\n",
      " Train LOSS : 0.0029535272624343634 R2 : 0.11637655645608902\n",
      "-VALID LOSS : 0.05124422907829285 R2 : 0.8772134184837341\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.045485734939575195,R2 : 0.8910113573074341\n",
      "[49/100]\n",
      " Train LOSS : 0.0028191942255944014 R2 : 0.11676876991987228\n",
      "-VALID LOSS : 0.045485734939575195 R2 : 0.8910113573074341\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04670887067914009,R2 : 0.8880805969238281\n",
      "[50/100]\n",
      " Train LOSS : 0.0028289593756198883 R2 : 0.11674025654792786\n",
      "-VALID LOSS : 0.04670887067914009 R2 : 0.8880805969238281\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.05051859840750694,R2 : 0.8789520859718323\n",
      "[51/100]\n",
      " Train LOSS : 0.0027284009847790003 R2 : 0.11703386157751083\n",
      "-VALID LOSS : 0.05051859840750694 R2 : 0.8789520859718323\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04811977222561836,R2 : 0.8846999406814575\n",
      "[52/100]\n",
      " Train LOSS : 0.0027257800102233887 R2 : 0.11704151332378387\n",
      "-VALID LOSS : 0.04811977222561836 R2 : 0.8846999406814575\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04236290976405144,R2 : 0.8984940052032471\n",
      "[53/100]\n",
      " Train LOSS : 0.00267346971668303 R2 : 0.11719424277544022\n",
      "-VALID LOSS : 0.04236290976405144 R2 : 0.8984940052032471\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04077901691198349,R2 : 0.9022891521453857\n",
      "[54/100]\n",
      " Train LOSS : 0.0026419467758387327 R2 : 0.11728627979755402\n",
      "-VALID LOSS : 0.04077901691198349 R2 : 0.9022891521453857\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.043593864887952805,R2 : 0.8955444693565369\n",
      "[55/100]\n",
      " Train LOSS : 0.0026302209589630365 R2 : 0.11732051521539688\n",
      "-VALID LOSS : 0.043593864887952805 R2 : 0.8955444693565369\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0450843870639801,R2 : 0.8919730186462402\n",
      "[56/100]\n",
      " Train LOSS : 0.0025855216663330793 R2 : 0.1174510270357132\n",
      "-VALID LOSS : 0.0450843870639801 R2 : 0.8919730186462402\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.04177790507674217,R2 : 0.8998957276344299\n",
      "[57/100]\n",
      " Train LOSS : 0.002591613680124283 R2 : 0.11743324249982834\n",
      "-VALID LOSS : 0.04177790507674217 R2 : 0.8998957276344299\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.038314420729875565,R2 : 0.9081946015357971\n",
      "[58/100]\n",
      " Train LOSS : 0.0025458813179284334 R2 : 0.11756676435470581\n",
      "-VALID LOSS : 0.038314420729875565 R2 : 0.9081946015357971\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03847436606884003,R2 : 0.9078113436698914\n",
      "[59/100]\n",
      " Train LOSS : 0.0025454056449234486 R2 : 0.11756815761327744\n",
      "-VALID LOSS : 0.03847436606884003 R2 : 0.9078113436698914\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0409264899790287,R2 : 0.9019358158111572\n",
      "[60/100]\n",
      " Train LOSS : 0.002519381931051612 R2 : 0.11764413863420486\n",
      "-VALID LOSS : 0.0409264899790287 R2 : 0.9019358158111572\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.041379764676094055,R2 : 0.9008496999740601\n",
      "[61/100]\n",
      " Train LOSS : 0.0025018928572535515 R2 : 0.11769519746303558\n",
      "-VALID LOSS : 0.041379764676094055 R2 : 0.9008496999740601\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03877386078238487,R2 : 0.9070937633514404\n",
      "[62/100]\n",
      " Train LOSS : 0.0024972176179289818 R2 : 0.11770884692668915\n",
      "-VALID LOSS : 0.03877386078238487 R2 : 0.9070937633514404\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.036626894026994705,R2 : 0.9122381210327148\n",
      "[63/100]\n",
      " Train LOSS : 0.002471688436344266 R2 : 0.11778338998556137\n",
      "-VALID LOSS : 0.036626894026994705 R2 : 0.9122381210327148\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.037118975073099136,R2 : 0.9110590219497681\n",
      "[64/100]\n",
      " Train LOSS : 0.0024732209276407957 R2 : 0.11777891218662262\n",
      "-VALID LOSS : 0.037118975073099136 R2 : 0.9110590219497681\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.039036329835653305,R2 : 0.9064648151397705\n",
      "[65/100]\n",
      " Train LOSS : 0.0024568154476583004 R2 : 0.11782681196928024\n",
      "-VALID LOSS : 0.039036329835653305 R2 : 0.9064648151397705\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03940046951174736,R2 : 0.9055923223495483\n",
      "[66/100]\n",
      " Train LOSS : 0.002449106192216277 R2 : 0.11784932017326355\n",
      "-VALID LOSS : 0.03940046951174736 R2 : 0.9055923223495483\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03756200149655342,R2 : 0.9099974632263184\n",
      "[67/100]\n",
      " Train LOSS : 0.0024468349292874336 R2 : 0.11785595118999481\n",
      "-VALID LOSS : 0.03756200149655342 R2 : 0.9099974632263184\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03597232699394226,R2 : 0.9138064980506897\n",
      "[68/100]\n",
      " Train LOSS : 0.002432694425806403 R2 : 0.11789724230766296\n",
      "-VALID LOSS : 0.03597232699394226 R2 : 0.9138064980506897\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03633652999997139,R2 : 0.9129338264465332\n",
      "[69/100]\n",
      " Train LOSS : 0.002433024113997817 R2 : 0.11789627373218536\n",
      "-VALID LOSS : 0.03633652999997139 R2 : 0.9129338264465332\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03783847764134407,R2 : 0.9093350172042847\n",
      "[70/100]\n",
      " Train LOSS : 0.002422730438411236 R2 : 0.11792632937431335\n",
      "-VALID LOSS : 0.03783847764134407 R2 : 0.9093350172042847\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03822245076298714,R2 : 0.9084149599075317\n",
      "[71/100]\n",
      " Train LOSS : 0.002415607450529933 R2 : 0.11794713139533997\n",
      "-VALID LOSS : 0.03822245076298714 R2 : 0.9084149599075317\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.036807890981435776,R2 : 0.9118044376373291\n",
      "[72/100]\n",
      " Train LOSS : 0.002411623951047659 R2 : 0.11795876175165176\n",
      "-VALID LOSS : 0.036807890981435776 R2 : 0.9118044376373291\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0354989692568779,R2 : 0.9149407148361206\n",
      "[73/100]\n",
      " Train LOSS : 0.002399159362539649 R2 : 0.11799515038728714\n",
      "-VALID LOSS : 0.0354989692568779 R2 : 0.9149407148361206\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03585165739059448,R2 : 0.9140956401824951\n",
      "[74/100]\n",
      " Train LOSS : 0.0023949034512043 R2 : 0.11800757795572281\n",
      "-VALID LOSS : 0.03585165739059448 R2 : 0.9140956401824951\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03711959347128868,R2 : 0.9110575318336487\n",
      "[75/100]\n",
      " Train LOSS : 0.002383643761277199 R2 : 0.11804044991731644\n",
      "-VALID LOSS : 0.03711959347128868 R2 : 0.9110575318336487\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03698186203837395,R2 : 0.91138756275177\n",
      "[76/100]\n",
      " Train LOSS : 0.0023750155232846737 R2 : 0.11806564778089523\n",
      "-VALID LOSS : 0.03698186203837395 R2 : 0.91138756275177\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.035837795585393906,R2 : 0.914128839969635\n",
      "[77/100]\n",
      " Train LOSS : 0.0023644601460546255 R2 : 0.11809646338224411\n",
      "-VALID LOSS : 0.035837795585393906 R2 : 0.914128839969635\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03523203358054161,R2 : 0.9155803322792053\n",
      "[78/100]\n",
      " Train LOSS : 0.0023541876580566168 R2 : 0.11812645196914673\n",
      "-VALID LOSS : 0.03523203358054161 R2 : 0.9155803322792053\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03584560379385948,R2 : 0.9141101241111755\n",
      "[79/100]\n",
      " Train LOSS : 0.002346169436350465 R2 : 0.11814986914396286\n",
      "-VALID LOSS : 0.03584560379385948 R2 : 0.9141101241111755\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.036497533321380615,R2 : 0.9125480651855469\n",
      "[80/100]\n",
      " Train LOSS : 0.0023346624802798033 R2 : 0.11818346381187439\n",
      "-VALID LOSS : 0.036497533321380615 R2 : 0.9125480651855469\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03593514487147331,R2 : 0.9138956069946289\n",
      "[81/100]\n",
      " Train LOSS : 0.0023258819710463285 R2 : 0.1182091012597084\n",
      "-VALID LOSS : 0.03593514487147331 R2 : 0.9138956069946289\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.035016827285289764,R2 : 0.9160959720611572\n",
      "[82/100]\n",
      " Train LOSS : 0.0023142348509281874 R2 : 0.11824310570955276\n",
      "-VALID LOSS : 0.035016827285289764 R2 : 0.9160959720611572\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03516565263271332,R2 : 0.9157393574714661\n",
      "[83/100]\n",
      " Train LOSS : 0.002304007299244404 R2 : 0.11827296763658524\n",
      "-VALID LOSS : 0.03516565263271332 R2 : 0.9157393574714661\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03597318381071091,R2 : 0.9138044714927673\n",
      "[84/100]\n",
      " Train LOSS : 0.0022915590088814497 R2 : 0.11830931156873703\n",
      "-VALID LOSS : 0.03597318381071091 R2 : 0.9138044714927673\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03581729158759117,R2 : 0.9141780138015747\n",
      "[85/100]\n",
      " Train LOSS : 0.0022789877839386463 R2 : 0.11834602057933807\n",
      "-VALID LOSS : 0.03581729158759117 R2 : 0.9141780138015747\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03492603078484535,R2 : 0.9163135290145874\n",
      "[86/100]\n",
      " Train LOSS : 0.002264846581965685 R2 : 0.11838730424642563\n",
      "-VALID LOSS : 0.03492603078484535 R2 : 0.9163135290145874\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03502602502703667,R2 : 0.9160739183425903\n",
      "[87/100]\n",
      " Train LOSS : 0.0022500038612633944 R2 : 0.11843064427375793\n",
      "-VALID LOSS : 0.03502602502703667 R2 : 0.9160739183425903\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.0358230285346508,R2 : 0.9141642451286316\n",
      "[88/100]\n",
      " Train LOSS : 0.0022333920933306217 R2 : 0.11847914755344391\n",
      "-VALID LOSS : 0.0358230285346508 R2 : 0.9141642451286316\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.035453613847494125,R2 : 0.9150493741035461\n",
      "[89/100]\n",
      " Train LOSS : 0.00221626996062696 R2 : 0.11852913349866867\n",
      "-VALID LOSS : 0.035453613847494125 R2 : 0.9150493741035461\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03470708429813385,R2 : 0.9168381690979004\n",
      "[90/100]\n",
      " Train LOSS : 0.0021970488596707582 R2 : 0.1185852587223053\n",
      "-VALID LOSS : 0.03470708429813385 R2 : 0.9168381690979004\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03536386415362358,R2 : 0.9152644276618958\n",
      "[91/100]\n",
      " Train LOSS : 0.0021780505776405334 R2 : 0.1186407208442688\n",
      "-VALID LOSS : 0.03536386415362358 R2 : 0.9152644276618958\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03562545403838158,R2 : 0.9146376252174377\n",
      "[92/100]\n",
      " Train LOSS : 0.002156452974304557 R2 : 0.11870378255844116\n",
      "-VALID LOSS : 0.03562545403838158 R2 : 0.9146376252174377\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03462257981300354,R2 : 0.9170406460762024\n",
      "[93/100]\n",
      " Train LOSS : 0.002134775510057807 R2 : 0.11876707524061203\n",
      "-VALID LOSS : 0.03462257981300354 R2 : 0.9170406460762024\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.035258542746305466,R2 : 0.9155167937278748\n",
      "[94/100]\n",
      " Train LOSS : 0.0021113527473062277 R2 : 0.1188354641199112\n",
      "-VALID LOSS : 0.035258542746305466 R2 : 0.9155167937278748\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03533955290913582,R2 : 0.9153227210044861\n",
      "[95/100]\n",
      " Train LOSS : 0.0020851215813308954 R2 : 0.11891204863786697\n",
      "-VALID LOSS : 0.03533955290913582 R2 : 0.9153227210044861\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03431980684399605,R2 : 0.9177660942077637\n",
      "[96/100]\n",
      " Train LOSS : 0.0020573162473738194 R2 : 0.11899323761463165\n",
      "-VALID LOSS : 0.03431980684399605 R2 : 0.9177660942077637\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03596184775233269,R2 : 0.9138315916061401\n",
      "[97/100]\n",
      " Train LOSS : 0.002027612878009677 R2 : 0.11907996237277985\n",
      "-VALID LOSS : 0.03596184775233269 R2 : 0.9138315916061401\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03316401690244675,R2 : 0.9205355048179626\n",
      "[98/100]\n",
      " Train LOSS : 0.0019958403427153826 R2 : 0.11917272210121155\n",
      "-VALID LOSS : 0.03316401690244675 R2 : 0.9205355048179626\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "pre_y.shape : torch.Size([12, 1])\n",
      "[Val] LOSS : 0.03912078216671944,R2 : 0.9062624573707581\n",
      "[99/100]\n",
      " Train LOSS : 0.001965434057638049 R2 : 0.11926150321960449\n",
      "-VALID LOSS : 0.03912078216671944 R2 : 0.9062624573707581\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 진행\n",
    "loss, r2 = training(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.11050643771886826,\n",
       "  0.05616157874464989,\n",
       "  0.033388663083314896,\n",
       "  0.059474777430295944,\n",
       "  0.036092039197683334,\n",
       "  0.029840275645256042,\n",
       "  0.03442634269595146,\n",
       "  0.03712105751037598,\n",
       "  0.03590769320726395,\n",
       "  0.03182058408856392,\n",
       "  0.02703195996582508,\n",
       "  0.02457721345126629,\n",
       "  0.025782383978366852,\n",
       "  0.026112983003258705,\n",
       "  0.021743260324001312,\n",
       "  0.016687268391251564,\n",
       "  0.015238749794661999,\n",
       "  0.015731578692793846,\n",
       "  0.014534001238644123,\n",
       "  0.011103211902081966,\n",
       "  0.007953658699989319,\n",
       "  0.00807584822177887,\n",
       "  0.008941047824919224,\n",
       "  0.006574244704097509,\n",
       "  0.004767171572893858,\n",
       "  0.005678031127899885,\n",
       "  0.005846660118550062,\n",
       "  0.003665560157969594,\n",
       "  0.002945281332358718,\n",
       "  0.004233397543430328,\n",
       "  0.004350272938609123,\n",
       "  0.003631020663306117,\n",
       "  0.003579590702429414,\n",
       "  0.003046884201467037,\n",
       "  0.003181656589731574,\n",
       "  0.0029097534716129303,\n",
       "  0.003044901182875037,\n",
       "  0.003062579780817032,\n",
       "  0.0029700181912630796,\n",
       "  0.0031655889470130205,\n",
       "  0.003045733319595456,\n",
       "  0.0031755445525050163,\n",
       "  0.0031241094693541527,\n",
       "  0.0031329079065471888,\n",
       "  0.0031418956350535154,\n",
       "  0.003042773576453328,\n",
       "  0.0030695830937474966,\n",
       "  0.0029336323495954275,\n",
       "  0.0029535272624343634,\n",
       "  0.0028191942255944014,\n",
       "  0.0028289593756198883,\n",
       "  0.0027284009847790003,\n",
       "  0.0027257800102233887,\n",
       "  0.00267346971668303,\n",
       "  0.0026419467758387327,\n",
       "  0.0026302209589630365,\n",
       "  0.0025855216663330793,\n",
       "  0.002591613680124283,\n",
       "  0.0025458813179284334,\n",
       "  0.0025454056449234486,\n",
       "  0.002519381931051612,\n",
       "  0.0025018928572535515,\n",
       "  0.0024972176179289818,\n",
       "  0.002471688436344266,\n",
       "  0.0024732209276407957,\n",
       "  0.0024568154476583004,\n",
       "  0.002449106192216277,\n",
       "  0.0024468349292874336,\n",
       "  0.002432694425806403,\n",
       "  0.002433024113997817,\n",
       "  0.002422730438411236,\n",
       "  0.002415607450529933,\n",
       "  0.002411623951047659,\n",
       "  0.002399159362539649,\n",
       "  0.0023949034512043,\n",
       "  0.002383643761277199,\n",
       "  0.0023750155232846737,\n",
       "  0.0023644601460546255,\n",
       "  0.0023541876580566168,\n",
       "  0.002346169436350465,\n",
       "  0.0023346624802798033,\n",
       "  0.0023258819710463285,\n",
       "  0.0023142348509281874,\n",
       "  0.002304007299244404,\n",
       "  0.0022915590088814497,\n",
       "  0.0022789877839386463,\n",
       "  0.002264846581965685,\n",
       "  0.0022500038612633944,\n",
       "  0.0022333920933306217,\n",
       "  0.00221626996062696,\n",
       "  0.0021970488596707582,\n",
       "  0.0021780505776405334,\n",
       "  0.002156452974304557,\n",
       "  0.002134775510057807,\n",
       "  0.0021113527473062277,\n",
       "  0.0020851215813308954,\n",
       "  0.0020573162473738194,\n",
       "  0.002027612878009677,\n",
       "  0.0019958403427153826,\n",
       "  0.001965434057638049],\n",
       " [0.5848502516746521,\n",
       "  0.31909462809562683,\n",
       "  0.44660958647727966,\n",
       "  0.2999894618988037,\n",
       "  0.2958374619483948,\n",
       "  0.3616058826446533,\n",
       "  0.3936042785644531,\n",
       "  0.38157984614372253,\n",
       "  0.3364756107330322,\n",
       "  0.27718114852905273,\n",
       "  0.23086445033550262,\n",
       "  0.21570420265197754,\n",
       "  0.206937775015831,\n",
       "  0.17850632965564728,\n",
       "  0.15567146241664886,\n",
       "  0.15936876833438873,\n",
       "  0.17383216321468353,\n",
       "  0.16620726883411407,\n",
       "  0.1273302435874939,\n",
       "  0.08005531877279282,\n",
       "  0.05709134042263031,\n",
       "  0.054549917578697205,\n",
       "  0.04672246053814888,\n",
       "  0.05504775047302246,\n",
       "  0.0822056457400322,\n",
       "  0.08912225812673569,\n",
       "  0.0609685480594635,\n",
       "  0.03615889325737953,\n",
       "  0.04220890998840332,\n",
       "  0.07514384388923645,\n",
       "  0.049551691859960556,\n",
       "  0.04590770602226257,\n",
       "  0.05418580397963524,\n",
       "  0.06167982146143913,\n",
       "  0.05365703999996185,\n",
       "  0.04635252431035042,\n",
       "  0.04746592044830322,\n",
       "  0.05624935403466225,\n",
       "  0.0637560486793518,\n",
       "  0.05849429592490196,\n",
       "  0.05180924013257027,\n",
       "  0.053657177835702896,\n",
       "  0.06205740198493004,\n",
       "  0.06267144531011581,\n",
       "  0.053925614804029465,\n",
       "  0.05055079981684685,\n",
       "  0.05503404140472412,\n",
       "  0.057909924536943436,\n",
       "  0.05124422907829285,\n",
       "  0.045485734939575195,\n",
       "  0.04670887067914009,\n",
       "  0.05051859840750694,\n",
       "  0.04811977222561836,\n",
       "  0.04236290976405144,\n",
       "  0.04077901691198349,\n",
       "  0.043593864887952805,\n",
       "  0.0450843870639801,\n",
       "  0.04177790507674217,\n",
       "  0.038314420729875565,\n",
       "  0.03847436606884003,\n",
       "  0.0409264899790287,\n",
       "  0.041379764676094055,\n",
       "  0.03877386078238487,\n",
       "  0.036626894026994705,\n",
       "  0.037118975073099136,\n",
       "  0.039036329835653305,\n",
       "  0.03940046951174736,\n",
       "  0.03756200149655342,\n",
       "  0.03597232699394226,\n",
       "  0.03633652999997139,\n",
       "  0.03783847764134407,\n",
       "  0.03822245076298714,\n",
       "  0.036807890981435776,\n",
       "  0.0354989692568779,\n",
       "  0.03585165739059448,\n",
       "  0.03711959347128868,\n",
       "  0.03698186203837395,\n",
       "  0.035837795585393906,\n",
       "  0.03523203358054161,\n",
       "  0.03584560379385948,\n",
       "  0.036497533321380615,\n",
       "  0.03593514487147331,\n",
       "  0.035016827285289764,\n",
       "  0.03516565263271332,\n",
       "  0.03597318381071091,\n",
       "  0.03581729158759117,\n",
       "  0.03492603078484535,\n",
       "  0.03502602502703667,\n",
       "  0.0358230285346508,\n",
       "  0.035453613847494125,\n",
       "  0.03470708429813385,\n",
       "  0.03536386415362358,\n",
       "  0.03562545403838158,\n",
       "  0.03462257981300354,\n",
       "  0.035258542746305466,\n",
       "  0.03533955290913582,\n",
       "  0.03431980684399605,\n",
       "  0.03596184775233269,\n",
       "  0.03316401690244675,\n",
       "  0.03912078216671944]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 후 loss 시각화\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(range(1,101),loss[0], label='Train')\n",
    "plt.plot(range(1,101),loss[1], label='Val')\n",
    "plt.title('Train & Valid')\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
