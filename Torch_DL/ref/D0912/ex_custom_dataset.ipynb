{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  사용자 정의 데이터셋\n",
    "- Pytorch에서 딥러닝 시 대량의 데이터 사용에 따른 부하(H/W, S/W) 및 많은 시간 소요에 대한 해결책으로 제시\n",
    "- 대량 데이터셋 전용 처리 모듈 제공\n",
    "- Dataset과 DataLoader\n",
    "    * DataSet => 데이텃 전처리, 텐서화 등의 작업 진행 \n",
    "    * DataLoader => Dataset 인스턴스를 사용해서 배치크기 만큼 데이터를 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "import torch                  \n",
    "import torch.nn as nn                 \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder              # 타겟 컬럼 수치화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 \n",
    "DATA_FILE = '../data/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV ==> DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 컬럼 수치화 ===> LabelEncoder \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(irisDF['variety'])\n",
    "irisDF['variety']=encoder.transform(irisDF['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 정의 데이터셋 클래스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# 클래스목적 : 학습용 데이터셋 텐서화 및 전처리\n",
    "# 클래스이름 : CustomDataSet\n",
    "# 부모클래스 : torch.utils.data.Dataset\n",
    "# 매개  변수 : featureDF, tagetDF\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        super().__init__()\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "    \n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 반환!!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS=torch.FloatTensor( self.featureDF.iloc[idx].values )\n",
    "        targetTS=torch.FloatTensor( self.targetDF.iloc[idx].values )\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 함수기능 : 파일 확장자별 데이터프레임 변환 기능 \n",
    "# 함수이름 : convertDataFrame\n",
    "# 매개변수 : data_path\n",
    "# 함수결과 : DataFrame\n",
    "# -------------------------------------------------------------\n",
    "def convertDataFrame(data_path, exit_header=0):\n",
    "    ext = data_path.rsplit('.')[-1]\n",
    "    if ext == 'csv':\n",
    "        return pd.read_csv(data_path, header=exit_header)\n",
    "    elif ext == 'json':\n",
    "        return pd.read_json(data_path, header=exit_header)\n",
    "    elif ext in ['xlsx', 'xls']:\n",
    "        return pd.read_excel(data_path, header=exit_header)\n",
    "    else: \n",
    "        return pd.read_table(data_path, header=exit_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/class02.csv\n",
      "   5.2  9.8\n",
      "0  3.0  2.1\n",
      "\n",
      "../data/iris.csv\n",
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH1='../data/class02.csv'\n",
    "dataDF = convertDataFrame(DATA_PATH1)\n",
    "print( DATA_PATH1, dataDF.head(1) , sep='\\n', end='\\n\\n')\n",
    "\n",
    "DATA_PATH2='../data/iris.csv'\n",
    "dataDF = convertDataFrame(DATA_PATH2)\n",
    "print( DATA_PATH2, dataDF.head(1) , sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 타겟 DF의 값이 숫자가 아닌경우 인코딩 진행 \n",
    "def check_type(targetDF):\n",
    "    if not targetDF.iloc[0].str.isnumeric().item():        \n",
    "        labels=targetDF[targetDF.columns[0]].unique().tolist()\n",
    "        label_index=dict(zip(labels, range(len(labels))))        \n",
    "        return targetDF[targetDF.columns[0]].replace(label_index).copy() \n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 클래스기능 : 파일기반 데이터셋\n",
    "# 클래스이름 : FileDataset\n",
    "# 매개  변수 : data_path  파일 경로 \n",
    "# 부모클래스 : utils.data.Dataset\n",
    "# -------------------------------------------------------------\n",
    "class FileDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        # 데이터파일 ==> DataFrame 변환\n",
    "        dataDF=convertDataFrame(data_path)\n",
    "        \n",
    "        # DataFrame ==> 피쳐와 타겟 추출\n",
    "        self.featuresDF=dataDF[dataDF.columns[:-1]]\n",
    "        self.targetDF=dataDF[dataDF.columns[-1:]]\n",
    "        \n",
    "        # 타겟 Series 정수 인코딩\n",
    "        result = check_type(self.targetDF[dataDF.columns[-1:]])\n",
    "        if result is not None: self.targetDF=result.to_frame()\n",
    "        \n",
    "        # 데이터셋의 행과 열 수 저장 \n",
    "        self.n_features=self.featuresDF.shape[1]\n",
    "        self.n_rows=self.featuresDF.shape[0]\n",
    "        \n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    \n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 반환!!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS=torch.FloatTensor( self.featuresDF.iloc[idx].values )\n",
    "        targetTS=torch.FloatTensor( self.targetDF.iloc[idx].values )\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [테스트]\n",
    "# IRIS 데이터셋 인스턴스 생성\n",
    "DATA_PATH='../data/iris.csv'\n",
    "irisFDS= FileDataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150, (150, 4), (150, 1))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 속성\n",
    "irisFDS.n_features,  irisFDS.n_rows, irisFDS.featuresDF.shape, irisFDS.targetDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variety\n",
       "0          50\n",
       "1          50\n",
       "2          50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisFDS.targetDF.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타겟 추출\n",
    "featureDF, targetDF =irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1:]]\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIS 데이터셋 인스턴스 생성\n",
    "irisDS= CustomDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 150)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 속성\n",
    "irisDS.n_features,  irisDS.n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0.]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRIS 데이터셋 메서드\n",
    "irisDS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터로더 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 것 : Dataset 인스턴스, Batch_size=1[기]\n",
    "irisDL=DataLoader(irisDS, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) torch.Size([2, 1])\n",
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000]])\n",
      "tensor([[0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "for dataTS, targetTS in irisDL:\n",
    "    print(dataTS.shape, targetTS.shape)\n",
    "    print(dataTS, targetTS, sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
