{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 예측 모델\n",
    "* 데이터 셋 : MNIST_test_csv, MNIST_train_csv\n",
    "* 피쳐/속성 : 그림 파일\n",
    "* 타겟/라벨 : 그림이 나타내는 번호\n",
    "* 학습-방법 : 지도학습 > 분류 > 다중분류\n",
    "* 알고리즘 : 인공신경망(ANN) -> MLP,DNN : 은닉층이 많은 구성\n",
    "* 프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "# - Model 관련\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "# - Data 및 시각화 관련\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 로딩\n",
    "TRAIN_FILE = '../data/MNIST_train.csv'\n",
    "TEST_FILE = '../data/MNIST_test.csv'\n",
    "\n",
    "### CSV >> DF\n",
    "MNIST_TRAIN_DF = pd.read_csv(TRAIN_FILE,header=None)\n",
    "MNIST_TEST_DF = pd.read_csv(TEST_FILE,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    7    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_TRAIN_DF.head(3)\n",
    "MNIST_TEST_DF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, 0 to 784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "MNIST_TEST_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, 0 to 784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "MNIST_TRAIN_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 9, 5, 6, 3, 8], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target column 값 확인하기\n",
    "MNIST_TEST_DF[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF \n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values) \n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF에서 피쳐와 타겟 추출\n",
    "Train_featureDF = MNIST_TRAIN_DF.drop(columns=0)\n",
    "Train_targetDF = MNIST_TRAIN_DF[0].to_frame()\n",
    "\n",
    "Test_featureDF = MNIST_TEST_DF.drop(columns=0)\n",
    "Test_targetDF = MNIST_TEST_DF[0].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       10000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "Train_targetDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "standard_scaler = StandardScaler()\n",
    "Train_standard_Scaled = standard_scaler.fit_transform(Train_featureDF)\n",
    "Test_featureDF_Scaled = standard_scaler.fit_transform(Test_featureDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_standard_Scaled.shape => (10000, 784)\n",
      "Test_featureDF_Scaled.shape => (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train_standard_Scaled.shape => {Train_standard_Scaled.shape}')\n",
    "print(f'Test_featureDF_Scaled.shape => {Test_featureDF_Scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 커스텀데이터셋 인스턴스 생성\n",
    "# MNIST_TRAIN_DS = MNIST_Dataset(Train_featureDF,Train_targetDF)\n",
    "# MNIST_TEST_DS = MNIST_Dataset(Test_featureDF,Test_targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비 <hr>\n",
    "- 학습_횟수 : EPOCH         <- 처음~끝까지 공부하는 단위\n",
    "- 배치_크기 : BATCH_SIZE    <- 한번에 학습할 데이터셋 양 \n",
    "- 위치_지정 : DEVICE    <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학_습_률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 100\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 설계 함수 즉, 생성자 메서드\n",
    "    def __init__(self, in_in, in_out, out_out, h_ins=[], h_outs=[]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layer=nn.Linear(in_in, h_ins[0] if len(h_ins) else in_out )\n",
    "        \n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for idx  in range(len(h_ins)):\n",
    "            self.h_layers.append( nn.Linear(h_ins[idx], h_outs[idx])  )\n",
    "        \n",
    "        self.out_layer=nn.Linear(h_outs[-1]  if len(h_outs) else in_out, out_out)\n",
    "        \n",
    "        \n",
    "    # 학습 진행 콜백 메서드\n",
    "    def forward(self, x): \n",
    "        # 입력층\n",
    "        y=self.in_layer(x)                  # y=x1w1+x2w2+x3w3+b\n",
    "        y=F.relu(y)                         # 0 <= y\n",
    "        #y=F.relu(self.in_layer(x) )\n",
    "\n",
    "        # 은닉층\n",
    "        for linear in self.h_layers:\n",
    "            y=linear(y)\n",
    "            y=F.relu(y) \n",
    "            #y=F.relu( linear(y) )\n",
    "            \n",
    "        # 출력층\n",
    "        return self.out_layer(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성 50 70 90   70 90 110\n",
    "h_ins_, h_outs_=[150,200,150], [200,150,100]\n",
    "m1=DynamicModel(in_in=784, in_out=5, out_out=10, h_ins=h_ins_, h_outs=h_outs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicModel(\n",
      "  (in_layer): Linear(in_features=784, out_features=150, bias=True)\n",
      "  (h_layers): ModuleList(\n",
      "    (0): Linear(in_features=150, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=150, bias=True)\n",
      "    (2): Linear(in_features=150, out_features=100, bias=True)\n",
      "  )\n",
      "  (out_layer): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS과 DL 인스턴스\n",
    "#- 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_val, y_train, y_val =train_test_split(Train_standard_Scaled, Train_targetDF, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train= pd.DataFrame(X_train)\n",
    "X_val=pd.DataFrame(X_val)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_val=pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 784) (10000, 784) (2500, 784)\n",
      "(7500, 1) (10000, 784) (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "trainDS=MNIST_Dataset(X_train, y_train)\n",
    "valDS=MNIST_Dataset(X_val, y_val)\n",
    "testDS=MNIST_Dataset(Test_featureDF, Test_targetDF)\n",
    "\n",
    "print(f'{X_train.shape} {Test_featureDF.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {Test_featureDF.shape} {y_val.shape}')\n",
    "\n",
    "# - 학습용 데이터로더 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-14\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서를 전달\n",
    "optimizer = optim.Adam(m1.parameters(),lr=LR)\n",
    "\n",
    "# 최적화 스케쥴링 인스턴스 생성 => lr 조절 및 성능 개선 여부 체크\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True) # score 사용 시\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=100, verbose=True)\n",
    "\n",
    "\n",
    "# 손실함수 인스턴스 => 다중분류 CrossEntropyLoss\n",
    "crossLoss = nn.CrossEntropyLoss()\n",
    "# multi_F1 = MulticlassF1Score(num_classes=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models 폴더 아래 프로젝트 폴더 아래 모델 파일 저장\n",
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH = '../models/MNIST/MCF/'\n",
    "# 저장 파일명\n",
    "SAVE_FILE = SAVE_PATH +'model_train_wbs.pth'\n",
    "# 모델 구조 및 파라미터 모두 저장 파일명\n",
    "SAVE_MODEL= SAVE_PATH +'model_all.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로상 폴더 존재 여부 체크\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH) # 폴더/폴더/... 하위 폴더 까지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784]) torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "for f, t in trainDL:\n",
    "    print(f.shape, t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100 => [TRAIN] LOSS: 0.6294927416245143 SCORE: 0.7974235946436723\n",
      "\t=> [VAL] LOSS: 0.3514135479927063 SCORE: 0.8981797695159912\n",
      "scheduler.num_bad_epochs => 0 scheduler.patience => 100\n",
      "1/100 => [TRAIN] LOSS: 0.2987623898188273 SCORE: 0.9096656680107117\n",
      "\t=> [VAL] LOSS: 0.3756755590438843 SCORE: 0.9175184965133667\n",
      "scheduler.num_bad_epochs => 1 scheduler.patience => 100\n",
      "2/100 => [TRAIN] LOSS: 0.24161204059918723 SCORE: 0.9311590464909871\n",
      "\t=> [VAL] LOSS: 0.40365928411483765 SCORE: 0.9062132239341736\n",
      "scheduler.num_bad_epochs => 2 scheduler.patience => 100\n",
      "3/100 => [TRAIN] LOSS: 0.22990323156118392 SCORE: 0.9378097462654114\n",
      "\t=> [VAL] LOSS: 0.41436585783958435 SCORE: 0.9193542003631592\n",
      "scheduler.num_bad_epochs => 3 scheduler.patience => 100\n",
      "4/100 => [TRAIN] LOSS: 0.2574780141313871 SCORE: 0.936433044274648\n",
      "\t=> [VAL] LOSS: 0.44723910093307495 SCORE: 0.9138697385787964\n",
      "scheduler.num_bad_epochs => 4 scheduler.patience => 100\n",
      "5/100 => [TRAIN] LOSS: 0.19003955890734991 SCORE: 0.9579088870684306\n",
      "\t=> [VAL] LOSS: 0.43105843663215637 SCORE: 0.921859622001648\n",
      "scheduler.num_bad_epochs => 5 scheduler.patience => 100\n",
      "6/100 => [TRAIN] LOSS: 0.1318625354145964 SCORE: 0.9662926117579143\n",
      "\t=> [VAL] LOSS: 0.4312836825847626 SCORE: 0.9236514568328857\n",
      "scheduler.num_bad_epochs => 6 scheduler.patience => 100\n",
      "7/100 => [TRAIN] LOSS: 0.1528851067274809 SCORE: 0.9624068888028463\n",
      "\t=> [VAL] LOSS: 0.4595656394958496 SCORE: 0.9173120856285095\n",
      "scheduler.num_bad_epochs => 7 scheduler.patience => 100\n",
      "8/100 => [TRAIN] LOSS: 0.12778366679946582 SCORE: 0.9703273860613505\n",
      "\t=> [VAL] LOSS: 0.5046517848968506 SCORE: 0.9334936141967773\n",
      "scheduler.num_bad_epochs => 8 scheduler.patience => 100\n",
      "9/100 => [TRAIN] LOSS: 0.1317923565333088 SCORE: 0.9707126275698343\n",
      "\t=> [VAL] LOSS: 0.6235034465789795 SCORE: 0.9175392985343933\n",
      "scheduler.num_bad_epochs => 9 scheduler.patience => 100\n",
      "10/100 => [TRAIN] LOSS: 0.19434342163304488 SCORE: 0.9608448195457459\n",
      "\t=> [VAL] LOSS: 0.5163597464561462 SCORE: 0.9227476119995117\n",
      "scheduler.num_bad_epochs => 10 scheduler.patience => 100\n",
      "11/100 => [TRAIN] LOSS: 0.11819780486325424 SCORE: 0.9678664485613505\n",
      "\t=> [VAL] LOSS: 0.6130979061126709 SCORE: 0.928887128829956\n",
      "scheduler.num_bad_epochs => 11 scheduler.patience => 100\n",
      "12/100 => [TRAIN] LOSS: 0.20271178738524517 SCORE: 0.9626971006393432\n",
      "\t=> [VAL] LOSS: 0.6763551235198975 SCORE: 0.9205141067504883\n",
      "scheduler.num_bad_epochs => 12 scheduler.patience => 100\n",
      "13/100 => [TRAIN] LOSS: 0.26235717634359995 SCORE: 0.9356685511271159\n",
      "\t=> [VAL] LOSS: 0.5634992122650146 SCORE: 0.9307639002799988\n",
      "scheduler.num_bad_epochs => 13 scheduler.patience => 100\n",
      "14/100 => [TRAIN] LOSS: 0.15021636868516605 SCORE: 0.9682561143239339\n",
      "\t=> [VAL] LOSS: 0.5336259007453918 SCORE: 0.9319514632225037\n",
      "scheduler.num_bad_epochs => 14 scheduler.patience => 100\n",
      "15/100 => [TRAIN] LOSS: 0.08906463482960437 SCORE: 0.9785109074910482\n",
      "\t=> [VAL] LOSS: 0.626576840877533 SCORE: 0.9303842782974243\n",
      "scheduler.num_bad_epochs => 15 scheduler.patience => 100\n",
      "16/100 => [TRAIN] LOSS: 0.06102038991482307 SCORE: 0.9858260679244996\n",
      "\t=> [VAL] LOSS: 0.7514843940734863 SCORE: 0.9377647042274475\n",
      "scheduler.num_bad_epochs => 16 scheduler.patience => 100\n",
      "17/100 => [TRAIN] LOSS: 0.05139413486525882 SCORE: 0.9869816644986471\n",
      "\t=> [VAL] LOSS: 0.603325366973877 SCORE: 0.9439656734466553\n",
      "scheduler.num_bad_epochs => 17 scheduler.patience => 100\n",
      "18/100 => [TRAIN] LOSS: 0.06223518776261092 SCORE: 0.9875557541847229\n",
      "\t=> [VAL] LOSS: 0.631119430065155 SCORE: 0.9401355385780334\n",
      "scheduler.num_bad_epochs => 18 scheduler.patience => 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 성능평가 계산\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m score\u001b[38;5;241m=\u001b[39mMulticlassF1Score(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)(pre_y, \u001b[43mtargetTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     28\u001b[0m score_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 최적화 진행\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTROY=[[],[]], [[],[]]\n",
    "\n",
    "## 학습 모니터링/스케줄링 설정 \n",
    "# => LOSS_HISTORY, SCORE_HISTROY 활용\n",
    "# => 임계기준 : 10번\n",
    "BREAK_CNT = 0\n",
    "LIMIT_VALUE = 10\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # 학습 모드로 모델 설정\n",
    "    m1.train()\n",
    "\n",
    "    # 배치크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0, 0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=m1(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=crossLoss(pre_y, targetTS.reshape(-1).long())\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능평가 계산\n",
    "        score=MulticlassF1Score(num_classes=10)(pre_y, targetTS.reshape(-1))\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    m1.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 추론/평가\n",
    "        pre_val=m1(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=crossLoss(pre_val, val_targetTS.reshape(-1).long())\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=MulticlassF1Score(num_classes=10)(pre_val, val_targetTS.reshape(-1))\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/len(trainDL))\n",
    "    SCORE_HISTROY[0].append(score_total/len(trainDL))\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTROY[1].append(score_val)\n",
    "\n",
    "    print(f'{epoch}/{EPOCH} => [TRAIN] LOSS: {LOSS_HISTORY[0][-1]} SCORE: {SCORE_HISTROY[0][-1]}')\n",
    "    print(f'\\t=> [VAL] LOSS: {LOSS_HISTORY[1][-1]} SCORE: {SCORE_HISTROY[1][-1]}')\n",
    "\n",
    "    # 성능이 좋은 학습 가중치 저장\n",
    "    SAVE_MODEL = f'loss({loss_total/len(trainDL):.5f})_score({score_total/len(trainDL):.5f}).pth'\n",
    "    # SAVE_FILE = f'model_train_wbs_{epoch}_{score_val}.pth'\n",
    "    if len(SCORE_HISTROY[1]) == 1:\n",
    "        # # 첫번째라서 무조건 모델 파라미터 저장\n",
    "        # torch.save(m1.state_dict(),SAVE_FILE)\n",
    "        # 모델 전체 저장\n",
    "        torch.save(m1,SAVE_PATH+SAVE_MODEL)\n",
    "    \n",
    "    else:\n",
    "        if SCORE_HISTROY[1][-1] > max(SCORE_HISTROY[1][:-1]):\n",
    "            # 두번째 ==> 첫번째보다 성능 좋으면 저장\n",
    "            # torch.save(m1.state_dict(),SAVE_FILE)\n",
    "            torch.save(m1,SAVE_PATH+SAVE_MODEL)\n",
    "    # 최적화 스케쥴러 인스턴스 업데이트\n",
    "    scheduler.step(loss_val)\n",
    "    print(f'scheduler.num_bad_epochs => {scheduler.num_bad_epochs}', end=' ')\n",
    "    print(f'scheduler.patience => {scheduler.patience}')\n",
    "\n",
    "    # 손실 감소(또는 성능 개선)이 안되는 경우 조기종료\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f'{scheduler.patience}EPOCH 성능 개선이 없어서 조기종료함')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
