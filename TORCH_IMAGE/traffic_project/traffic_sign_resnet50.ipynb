{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 도로 표지판 분류 모델 만들기 <hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch Ver.:2.4.1+cu118\n",
      "pandas Ver.:2.0.3\n",
      "numpy Ver.:1.24.4\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 모델링 관련 모듈 로딩\n",
    "# ---------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 데이터 분석 관련 모듈 로딩\n",
    "# ---------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 이미지 관련 모듈 로딩\n",
    "# ---------------------------------------------------------------------\n",
    "from torchvision import transforms\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 기타 모듈 로딩\n",
    "# ---------------------------------------------------------------------\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 활용 패키지 버전 체크\n",
    "print(f'torch Ver.:{torch.__version__}')\n",
    "print(f'pandas Ver.:{pd.__version__}')\n",
    "print(f'numpy Ver.:{np.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   data0.pickle - 셔플링\n",
    "*   data1.pickle - 셔플링, /255.0 정규화\n",
    "*   data2.pickle - 셔플링, /255.0 + 평균 정규화\n",
    "*   data3.pickle - 셔플링, /255.0 + 평균 + STD 정규화\n",
    "*   data4.pickle - 회색조, 셔플링\n",
    "*   data5.pickle - 회색조, 셔플링, 로컬 히스토그램 평준화\n",
    "*   data6.pickle - 회색조, 셔플링, 로컬 히스토그램 평준화, /255.0 정규화\n",
    "*   data7.pickle - 회색조, 셔플링, 로컬 히스토그램 평준화, /255.0 + 평균 정규화\n",
    "*   data8.pickle - 회색조, 셔플링, 로컬 히스토그램 평준화, /255.0 + 평균 + STD 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: dict_keys(['x_train', 'y_test', 'x_test', 'x_validation', 'labels', 'y_train', 'y_validation'])\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정 및 데이터 로드\n",
    "BASE_DIR = r\"C:\\Users\\Administrator\\Desktop\\장재웅\\traffic_sign_data\"\n",
    "file_path = os.path.join(BASE_DIR, 'data1.pickle')\n",
    "\n",
    "# pickle 파일 로드\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "print('keys:', data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data['x_train']  # shape: (86989, 32, 3, 32)\n",
    "y_train = data['y_train']  # shape: (86989,)\n",
    "\n",
    "x_test = data['x_test']    # shape: (12630, 32, 3, 32)\n",
    "y_test = data['y_test']    # shape: (12630,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86989, 3, 32, 32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.transpose(0, 2, 1, 3)\n",
    "x_test = x_test.transpose(0, 2, 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86989, 32, 3, 32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (86989, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.transpose(0, 3, 1, 2)  # (N, H, W, C) → (N, C, H, W)\n",
    "x_test = x_test.transpose(0, 3, 1, 2)\n",
    "\n",
    "print(\"Final shape:\", x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageDataset(Dataset):\n",
    "#     def __init__(self, features, targets, transform=None):\n",
    "#         super().__init__()\n",
    "#         self.features = features\n",
    "#         self.targets = targets\n",
    "#         self.n_rows = features.shape[0]\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.n_rows\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # 변환된 이미지와 타겟 반환\n",
    "#         featureTS = self.features[index]\n",
    "#         targetTS = torch.tensor(self.targets[index], dtype=torch.long)  # torch.uint8 -> torch.long\n",
    "\n",
    "#         # 이미지 전처리(정규화 및 텐서 변환)\n",
    "#         if self.transform:\n",
    "#             featureTS = self.transform(featureTS)\n",
    "\n",
    "#         return featureTS, targetTS\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, features, targets, transform=None):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.n_rows = features.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]  # NumPy 배열 그대로 유지\n",
    "        target = self.targets[index]\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "\n",
    "        return feature, torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "\n",
    "# 데이터 전처리 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),            # 텐서를 PIL 이미지로 변환\n",
    "    transforms.Resize((256, 256)),      # 크기 조정\n",
    "    transforms.CenterCrop(224),         # 중앙 자르기\n",
    "    transforms.ToTensor(),              # 다시 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 셋 생성\n",
    "train_dataset = ImageDataset(x_train, y_train, transform=transform)\n",
    "test_dataset = ImageDataset(x_test, y_test, transform=transform)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사전 훈련 모델 들고 오기 <hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사전학습된 모델 로딩\n",
    "model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features.0.weight] - torch.Size([64, 3, 3, 3])\n",
      "[features.0.bias] - torch.Size([64])\n",
      "[features.2.weight] - torch.Size([64, 64, 3, 3])\n",
      "[features.2.bias] - torch.Size([64])\n",
      "[features.5.weight] - torch.Size([128, 64, 3, 3])\n",
      "[features.5.bias] - torch.Size([128])\n",
      "[features.7.weight] - torch.Size([128, 128, 3, 3])\n",
      "[features.7.bias] - torch.Size([128])\n",
      "[features.10.weight] - torch.Size([256, 128, 3, 3])\n",
      "[features.10.bias] - torch.Size([256])\n",
      "[features.12.weight] - torch.Size([256, 256, 3, 3])\n",
      "[features.12.bias] - torch.Size([256])\n",
      "[features.14.weight] - torch.Size([256, 256, 3, 3])\n",
      "[features.14.bias] - torch.Size([256])\n",
      "[features.16.weight] - torch.Size([256, 256, 3, 3])\n",
      "[features.16.bias] - torch.Size([256])\n",
      "[features.19.weight] - torch.Size([512, 256, 3, 3])\n",
      "[features.19.bias] - torch.Size([512])\n",
      "[features.21.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.21.bias] - torch.Size([512])\n",
      "[features.23.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.23.bias] - torch.Size([512])\n",
      "[features.25.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.25.bias] - torch.Size([512])\n",
      "[features.28.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.28.bias] - torch.Size([512])\n",
      "[features.30.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.30.bias] - torch.Size([512])\n",
      "[features.32.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.32.bias] - torch.Size([512])\n",
      "[features.34.weight] - torch.Size([512, 512, 3, 3])\n",
      "[features.34.bias] - torch.Size([512])\n",
      "[classifier.0.weight] - torch.Size([4096, 25088])\n",
      "[classifier.0.bias] - torch.Size([4096])\n",
      "[classifier.3.weight] - torch.Size([4096, 4096])\n",
      "[classifier.3.bias] - torch.Size([4096])\n",
      "[classifier.6.weight] - torch.Size([1000, 4096])\n",
      "[classifier.6.bias] - torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "### 사전학습된 모델의 파라미터 비활성화 설정\n",
    "for named, param in model.named_parameters():\n",
    "    print(f'[{named}] - {param.shape}')\n",
    "    # 역전파 시에 업데이트 되지 않도록 설정\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(4096, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 43)  # 최종 클래스 수 43\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=43, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.weight] - torch.Size([512, 4096])\n",
      "[0.bias] - torch.Size([512])\n",
      "[3.weight] - torch.Size([43, 512])\n",
      "[3.bias] - torch.Size([43])\n"
     ]
    }
   ],
   "source": [
    "# classifier 파라미터 활성화 설정\n",
    "for named, param in model.classifier[6].named_parameters():\n",
    "    print(f'[{named}] - {param.shape}')\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models 폴더 아래 프로젝트 폴더 아래 모델 파일 저장\n",
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH = 'traffic_sign_model/'\n",
    "# 저장 파일명\n",
    "SAVE_FILE = SAVE_PATH +'model_train_wbs.pth'\n",
    "# 모델 구조 및 파라미터 모두 저장 파일명\n",
    "SAVE_MODEL= SAVE_PATH +'model_all.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장 폴더 존재 여부 체크 후 생성\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 장치 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스\n",
    "optimizer = torch.optim.Adam(model.classifier[6].parameters(), lr=0.01)\n",
    "\n",
    "# 손실함수 인스턴스\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 스케쥴링 인스턴스 생성 => lr 조절 및 성능 개선 여부 체크\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=15, verbose=True) # score 사용 시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTROY = [[], []], [[], []]\n",
    "\n",
    "EPOCH = 10\n",
    "f1_score_metric = MulticlassF1Score(num_classes=43).to(device)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "    # 배치크기 만큼 데이터 로딩해서 학습 진행\n",
    "    train_loss_total, train_score_total = 0, 0\n",
    "    val_loss_total, val_score_total = 0, 0\n",
    "\n",
    "    for featureTS, targetTS in train_loader:\n",
    "        # 텐서를 CUDA로 이동\n",
    "        featureTS = featureTS.to(device)\n",
    "        targetTS = targetTS.to(device)\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y = model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_func(pre_y, targetTS)\n",
    "        train_loss_total += loss.item()\n",
    "\n",
    "        # 성능 평가 계산\n",
    "        score = f1_score_metric(torch.argmax(pre_y, dim=1), targetTS)\n",
    "        train_score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_featureTS, val_targetTS in test_loader:\n",
    "            # 텐서를 CUDA로 이동\n",
    "            val_featureTS = val_featureTS.to(device)\n",
    "            val_targetTS = val_targetTS.to(device)\n",
    "\n",
    "            # 추론/평가\n",
    "            pre_val = model(val_featureTS)\n",
    "\n",
    "            # 손실\n",
    "            loss_val = loss_func(pre_val, val_targetTS)\n",
    "            val_loss_total += loss_val.item()\n",
    "\n",
    "            # 성능 평가\n",
    "            score_val = f1_score_metric(torch.argmax(pre_val, dim=1), val_targetTS)\n",
    "            val_score_total += score_val.item()\n",
    "\n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(train_loss_total / len(train_loader))\n",
    "    SCORE_HISTROY[0].append(train_score_total / len(train_loader))\n",
    "\n",
    "    LOSS_HISTORY[1].append(val_loss_total / len(test_loader))\n",
    "    SCORE_HISTROY[1].append(val_score_total / len(test_loader))\n",
    "\n",
    "\n",
    "    print(f'{epoch}/{EPOCH} => [TRAIN] LOSS: {LOSS_HISTORY[0][-1]} SCORE: {SCORE_HISTROY[0][-1]}')\n",
    "    print(f'\\t=> [VAL] LOSS: {LOSS_HISTORY[1][-1]} SCORE: {SCORE_HISTROY[1][-1]}')\n",
    "\n",
    "    # 성능이 좋은 학습 가중치 저장\n",
    "    average_train_loss = val_loss_total / len(val_loader)\n",
    "    average_train_score = val_score_total / len(val_loader)\n",
    "\n",
    "    SAVE_MODEL = f'loss({average_train_loss:.5f})_score({average_train_score:.5f}).pth'\n",
    "\n",
    "    if len(SCORE_HISTROY[1]) == 1:\n",
    "        # 첫번째라서 무조건 모델 파라미터 저장\n",
    "        torch.save(model, SAVE_PATH + SAVE_MODEL)\n",
    "    else:\n",
    "        if SCORE_HISTROY[1][-1] > max(SCORE_HISTROY[1][:-1]):\n",
    "            torch.save(model, SAVE_PATH + SAVE_MODEL)\n",
    "\n",
    "\n",
    "# 에포크 범위 생성\n",
    "epoch_range = range(1, EPOCH + 1)\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_range, LOSS_HISTORY[0], 'r-', label='Train')\n",
    "plt.plot(epoch_range, LOSS_HISTORY[1], 'b-', label='Valid')\n",
    "plt.grid()\n",
    "plt.title('Loss over EPOCH')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_range, SCORE_HISTROY[0], 'r-', label='Train')\n",
    "plt.plot(epoch_range, SCORE_HISTROY[1], 'b-', label='Valid')\n",
    "plt.grid()\n",
    "plt.title('F1_Score over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1_Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # 최적화 스케쥴러 인스턴스 업데이트\n",
    "    # scheduler.step(loss_val)\n",
    "    # print(f'scheduler.num_bad_epochs => {scheduler.num_bad_epochs}', end=' ')\n",
    "    # print(f'scheduler.patience => {scheduler.patience}')\n",
    "\n",
    "    # 손실 감소(또는 성능 개선)이 안되는 경우 조기종료\n",
    "    # if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "    #     print(f'{scheduler.patience}EPOCH 성능 개선이 없어서 조기종료함')\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, loss_func, optimizer, DEVICE, num_epochs=1, is_train=True):\n",
    "#     f1score_func = MulticlassF1Score(num_classes=43).to(DEVICE)\n",
    "#     since = time.time()\n",
    "#     loss_history = [],[]\n",
    "#     acc_history = [],[]\n",
    "#     best_acc = 0.0\n",
    "#     # num_epochs = 5\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # 학습 모드로 모델 설정\n",
    "#         model.train()\n",
    "\n",
    "#         print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         running_corrects = 0\n",
    "#         running_loss = 0.0\n",
    "        \n",
    "#         score_total = 0\n",
    "\n",
    "#         for featureTS, targetTS in train_loader:\n",
    "\n",
    "#             # DEVICE : CPU/GPU 사용\n",
    "#             featureTS=featureTS.to(DEVICE)\n",
    "#             targetTS=targetTS.to(DEVICE)\n",
    "            \n",
    "#             # 학습 진행\n",
    "#             pre_y = model(featureTS)\n",
    "\n",
    "#             # 손실 계산\n",
    "#             loss = loss_func(pre_y, targetTS)\n",
    "\n",
    "#             # # 예제 점수계산법\n",
    "#             _, preds = torch.max(pre_y, 1)\n",
    "\n",
    "#             # 성능평가 계산\n",
    "#             score=f1score_func(pre_y, targetTS.reshape(-1))\n",
    "#             score_total += score.item()\n",
    "\n",
    "#             # 최적화 진행\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_corrects += torch.sum(preds == targetTS.data)\n",
    "#             # running_loss += loss.item() * featureTS.size(0) # loss값 * batch_size\n",
    "#             running_loss += loss.item() \n",
    "\n",
    "#         # 검증 모드로 모델 설정\n",
    "#         model.eval()\n",
    "\n",
    "#         running_val_corrects = 0\n",
    "#         running_val_loss = 0.0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             # 검증 데이터셋\n",
    "#             for feature, target in test_loader:\n",
    "                \n",
    "#                 # CPU/GPU 사용\n",
    "#                 feature=feature.to(DEVICE)\n",
    "#                 target=target.to(DEVICE)\n",
    "\n",
    "#                 # 평가\n",
    "#                 pre_val=model(feature)\n",
    "\n",
    "#                 # 손실\n",
    "#                 loss_val=loss_func(pre_val, target.reshape(-1).long())\n",
    "\n",
    "#                 # 성능평가\n",
    "#                 score_val=f1score_func(pre_val, target.reshape(-1))\n",
    "            \n",
    "#             running_val_corrects+=score_val.item()\n",
    "#             running_val_loss+=loss_val.item()\n",
    "\n",
    "#         epoch_acc = running_corrects.double() / len(train_loader)\n",
    "#         epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "#         print('[TRAIN] LOSS: {:.4f} SCORE: {:.4f}'.format(epoch_loss, score_total/len(train_loader))) \n",
    "#         print('[VAL] LOSS: {:.4f} SCORE: {:.4f}'.format(running_val_loss, running_val_corrects))\n",
    "\n",
    "#         if epoch_acc > best_acc:\n",
    "#             best_acc = epoch_acc\n",
    "\n",
    "#         loss_history[0].append(epoch_loss)        \n",
    "#         acc_history[0].append(score_total/len(train_loader))\n",
    "\n",
    "#         loss_history[1].append(running_val_loss)\n",
    "#         acc_history[1].append(running_val_corrects)\n",
    "\n",
    "#         ### 모델 저장 부분\n",
    "#         # 끝나는 시간 저장\n",
    "#         end_time = time.strftime('%y.%m.%d..%H_%M_%S')\n",
    "\n",
    "#         # 모델 파라미터 저장\n",
    "#         if len(acc_history[1]) == 1:\n",
    "#             torch.save(model.state_dict(), os.path.join('./models/', '{0:0=2d}_{1}.pth'.format(epoch+1, end_time)))\n",
    "#         else:\n",
    "#             if acc_history[1][-1] > max(acc_history[1][:-1]):\n",
    "#                 torch.save(model.state_dict(), os.path.join('./models/', '{0:0=2d}_{1}.pth'.format(epoch+1, end_time)))\n",
    "#         print()\n",
    "\n",
    "#         # 모델 경로 지정\n",
    "#         SAVE_PATH = './models'\n",
    "#         SAVE_MODEL = f'/model_num_loss({running_val_loss:.4f})_score({running_val_corrects:.4f}).pth'\n",
    "        \n",
    "#         # 모델 전체 저장\n",
    "#         if len(acc_history[1]) == 1:\n",
    "#             torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "#         else:\n",
    "#             if acc_history[1][-1] > max(acc_history[1][:-1]):\n",
    "#                 torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "\n",
    "#         # 최적화 스케쥴러 인스턴스 업데이트\n",
    "#         scheduler.step(loss_val)\n",
    "#         print(f'scheduler.num_bad_epochs => {scheduler.num_bad_epochs}', end=' ')\n",
    "#         print(f'scheduler.patience => {scheduler.patience}')\n",
    "\n",
    "#         # # 손실 감소(또는 성능 개선)이 안되는 경우 조기종료\n",
    "#         # if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "#         #     print(f'{scheduler.patience}EPOCH 성능 개선이 없어서 조기종료함')\n",
    "#         #     break\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print('모델 학습 시간: {:.0f}분 {:.0f}초'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "# \t### 학습 & 검증 결과 그래프로 출력\n",
    "#     epochs = range(1, len(acc_history[1]) + 1)\n",
    "    \n",
    "# \t# Loss\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs, loss_history[0], 'r-', label='Train')\n",
    "#     plt.plot(epochs, loss_history[1], 'b-', label='Valid')\n",
    "#     plt.grid()\n",
    "#     plt.title('Loss over Epochs')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Accuracy\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs, acc_history[0], 'r-', label='Train')\n",
    "#     plt.plot(epochs, acc_history[1], 'b-', label='Valid')\n",
    "#     plt.grid()\n",
    "#     plt.title('F1_Score over Epochs')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('F1_Score')\n",
    "#     plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
